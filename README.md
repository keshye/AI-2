# QUESTION1
TensorFlow is an open-source machine learning framework developed by Google Brain. It is widely used for deep learning, numerical computation, and large-scale machine learning applications.

Key Features:

Computation Graphs: Uses static and dynamic graphs for computation.
Scalability: Runs on CPUs, GPUs, and TPUs.
Eager Execution: Allows immediate computation for ease of debugging.
Automatic Differentiation: Uses tf.GradientTape for backpropagation.
Model Deployment: Supports TensorFlow Lite (mobile), TensorFlow.js (web), and TensorFlow Serving (production).
Pretrained Models: Offers TensorFlow Hub and Model Garden for transfer learning.

#QUESTION2
TensorFlow: Uses static computation graphs, meaning the entire model is built and optimized before execution. This improves performance but makes debugging harder.
PyTorch: Uses dynamic computation graphs, where operations are executed immediately, making debugging and experimentation more flexible.

#QUESTION3
Keras is a high-level deep learning API designed for easy and fast model building.

Supported Backends:

TensorFlow (default backend)
Microsoft Cognitive Toolkit (CNTK) (deprecated)
Theano (deprecated)
PlaidML (for OpenCL-based computation)

#QUESTION4
Scikit-learn is a machine learning library built on NumPy, SciPy, and Matplotlib.

Key Features:

Supervised & Unsupervised Learning (classification, regression, clustering)
Model Selection & Evaluation (cross-validation, hyperparameter tuning)
Feature Engineering (normalization, encoding, feature extraction)
Scalability (parallel computing with joblib)
Integration with Pandas & NumPy

#QUESTION5
Jupyter Notebooks are interactive computing environments for data science and research.

Key Features:

Live Code Execution: Run Python, R, Julia, and more.
Markdown Support: Write formatted text alongside code.
Data Visualization: Supports Matplotlib, Seaborn, Plotly, etc.
Notebook Sharing: Export to HTML, PDF, and Markdown.
Integration with Machine Learning Libraries

#QUESTION6
The Dropout layer prevents overfitting by randomly deactivating neurons during training, forcing the network to learn more generalized patterns.

#QUESTION7
The optimizer updates model weights using computed gradients to minimize loss.

Common Optimizer Used: torch.optim.Adam (Adaptive Moment Estimation), which combines momentum and adaptive learning rates for efficient optimization.

#QUESTION8
The Conv2D layer applies convolutional filters to detect patterns such as edges, shapes, and textures in images.

#QUESTION9
Model Type: Logistic Regression, Decision Tree, or Random Forest.
Dataset: Typically, the Iris dataset (classification) or Boston Housing dataset (regression).

#QUESTION10
Output: A graph, chart, or visualization.
Library Used: Matplotlib, Seaborn, or Plotly.
